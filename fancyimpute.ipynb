{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOocQjqxc9K/88flDbcknP2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##FancyImpute\n",
        "\n",
        "**Fancyimpute** is a Python library that provides various advanced imputation techniques for handling missing data. It offers a range of algorithms to fill in missing values in datasets, allowing users to choose the most appropriate method based on their data and requirements.\n",
        "\n",
        "Here are a few key features and techniques provided by Fancyimpute:\n",
        "\n",
        "**Matrix Completion:** Fancyimpute offers matrix completion algorithms, such as SoftImpute and NuclearNormMinimization, which aim to estimate the missing values in a dataset based on the observed values and underlying patterns. These methods leverage low-rank matrix approximation techniques to fill in missing entries.\n",
        "\n",
        "**Multiple Imputation:** Fancyimpute supports multiple imputation techniques, including MICE (Multivariate Imputation by Chained Equations). MICE imputes missing values iteratively by modeling each variable with missing data conditional on the other variables.\n",
        "\n",
        "**K-Nearest Neighbors (KNN):** The library provides a KNN imputation method that estimates missing values by finding the K-nearest neighbors of each sample and imputing missing entries based on the values of the nearest neighbors.\n",
        "\n",
        "**Deep Learning:**Fancyimpute incorporates deep learning techniques for imputation, such as using an autoencoder network to learn patterns and relationships in the data and fill in missing values based on the learned representations.\n",
        "\n",
        "**Time Series Imputation:** The library includes methods specifically designed for handling missing values in time series data, such as Temporal Fusion Transformers (TFT), which leverage deep learning models to impute missing values in temporal sequences.\n",
        "\n"
      ],
      "metadata": {
        "id": "yzMYvcMQtHaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install fancyimpute"
      ],
      "metadata": {
        "id": "W_0147xgtW2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwgIiKLytGMZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from fancyimpute import SoftImpute\n",
        "\n",
        "# Create a matrix with missing values\n",
        "X = np.array([[1, 2, np.nan],\n",
        "              [3, np.nan, 5],\n",
        "              [np.nan, 6, 7]])\n",
        "\n",
        "# Initialize and fit the SoftImpute model\n",
        "imputer = SoftImpute()\n",
        "X_imputed = imputer.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_imputed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msBVsLfZuRhQ",
        "outputId": "46048717-e3e6-46ec-ed6b-e59247931c44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 2.        , 2.11955007],\n",
              "       [3.        , 4.10710043, 5.        ],\n",
              "       [3.7202454 , 6.        , 7.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  MICE (Multivariate Imputation by Chained Equations) \n",
        "\n",
        "MICE imputation is performed using regression models by default. However, you can also specify a different imputation model by passing it to the estimator parameter of IterativeImputer. For example, you can use a random forest regressor by setting estimator=RandomForestRegressor()"
      ],
      "metadata": {
        "id": "Gmcmg-8OutY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from fancyimpute import IterativeImputer\n",
        "\n",
        "# Create a matrix with missing values\n",
        "X = np.array([[1, 2, np.nan],\n",
        "              [3, np.nan, 5],\n",
        "              [np.nan, 6, 7]])\n",
        "\n",
        "# Initialize and fit the MICE imputer\n",
        "imputer = IterativeImputer()\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "print(X_imputed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLFOsiMIvFiH",
        "outputId": "99da999d-9187-47a3-f86d-c419e9dc6fae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         2.         2.52179554]\n",
            " [3.         4.21386896 5.        ]\n",
            " [4.61466492 6.         7.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Happy Learning !!\n",
        "You can connect and follow me @\n",
        "  * [LinkedIn](https://www.linkedin.com/in/priya-singh1803)\n",
        "  * [Github](https://github.com/piyu18/)\n",
        "  * [Analytics Vidhya](https://www.analyticsvidhya.com/blog/author/priya203/)\n"
      ],
      "metadata": {
        "id": "DuA4Eq35vL7u"
      }
    }
  ]
}